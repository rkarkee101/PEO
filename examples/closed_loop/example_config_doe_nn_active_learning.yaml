project:
  name: process-engineering-optimizer

storage:
  root: ./storage

logging:
  level: INFO

data:
  delimiter: ","
  encoding: "utf-8"
  tool_parameters: [temperature_C, pressure_mTorr, power_W, flow_sccm, gas]
  target_properties: [thickness_nm, sheet_resistance_ohm]
  categorical_params:
    gas: []

doe:
  # Prefer space-filling DOE when you intend to do active learning.
  methods: [latin_hypercube]
  n_samples: 24
  interaction_depth: 2

doe_to_ml:
  enabled: true
  selection:
    p_value_threshold: 0.15
    top_k: 8
    keep_at_least: 3
  interactions:
    enabled: true
    p_value_threshold: 0.15
    top_k: 10
  quadratic:
    enabled: true
    p_value_threshold: 0.20
    top_k: 6

training:
  # The DOE-informed neural hybrid (RSM trend + NN residual) is a good default for DOE-sized data.
  models: [rsm_mlp]
  autotune: true
  max_tuning_trials: 25
  cv_folds: 5
  random_state: 42
  overfit_guard:
    max_train_test_r2_gap: 0.15
  uncertainty_calibration:
    enabled: true
    method: quantile
    target_coverage: 0.6827
    min_std: 1.0e-9

inverse_design:
  # For closed-loop, start with random for speed; switch to bayesopt when your model is stable.
  method: random
  search_budget: 4000
  top_k: 10
  lambda_uncertainty: 0.35
  lambda_ood: 0.25
  diversity:
    enabled: true
    min_distance: 0.12

mobo:
  enabled: false

rag:
  retriever: tfidf
  top_k: 6
